{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('dev': conda)"
  },
  "interpreter": {
   "hash": "38e719a702c56ff7695290ab132eef83c1b4d5a17b776384c2f7168698ff0a3a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Team Pos  Age   G   AB   R    H  2B  3B  HR  ...  CS  BB  \\\n",
       "Player                                                          ...           \n",
       "Isiah Kiner-Falefa  TEX  SS   26  97  388  46  100  17   2   6  ...   2  13   \n",
       "Tommy Edman         STL  2B   26  96  387  50   99  20   3   6  ...   4  22   \n",
       "Bo Bichette         TOR  SS   23  93  380  73  110  18   1  16  ...   0  25   \n",
       "Adam Frazier        PIT  2B   29  96  377  56  123  27   4   4  ...   4  34   \n",
       "Whit Merrifield      KC  2B   32  95  377  54  103  21   2   8  ...   1  28   \n",
       "\n",
       "                    SO  SH  SF  HBP    AVG    OBP    SLG    OPS  \n",
       "Player                                                           \n",
       "Isiah Kiner-Falefa  66   1   2    7  0.258  0.293  0.358  0.651  \n",
       "Tommy Edman         53   1   1    3  0.256  0.300  0.370  0.670  \n",
       "Bo Bichette         86   0   1    4  0.289  0.339  0.468  0.807  \n",
       "Adam Frazier        45   0   1    6  0.326  0.390  0.451  0.841  \n",
       "Whit Merrifield     56   0   9    3  0.273  0.321  0.403  0.724  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Team</th>\n      <th>Pos</th>\n      <th>Age</th>\n      <th>G</th>\n      <th>AB</th>\n      <th>R</th>\n      <th>H</th>\n      <th>2B</th>\n      <th>3B</th>\n      <th>HR</th>\n      <th>...</th>\n      <th>CS</th>\n      <th>BB</th>\n      <th>SO</th>\n      <th>SH</th>\n      <th>SF</th>\n      <th>HBP</th>\n      <th>AVG</th>\n      <th>OBP</th>\n      <th>SLG</th>\n      <th>OPS</th>\n    </tr>\n    <tr>\n      <th>Player</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Isiah Kiner-Falefa</th>\n      <td>TEX</td>\n      <td>SS</td>\n      <td>26</td>\n      <td>97</td>\n      <td>388</td>\n      <td>46</td>\n      <td>100</td>\n      <td>17</td>\n      <td>2</td>\n      <td>6</td>\n      <td>...</td>\n      <td>2</td>\n      <td>13</td>\n      <td>66</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0.258</td>\n      <td>0.293</td>\n      <td>0.358</td>\n      <td>0.651</td>\n    </tr>\n    <tr>\n      <th>Tommy Edman</th>\n      <td>STL</td>\n      <td>2B</td>\n      <td>26</td>\n      <td>96</td>\n      <td>387</td>\n      <td>50</td>\n      <td>99</td>\n      <td>20</td>\n      <td>3</td>\n      <td>6</td>\n      <td>...</td>\n      <td>4</td>\n      <td>22</td>\n      <td>53</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.256</td>\n      <td>0.300</td>\n      <td>0.370</td>\n      <td>0.670</td>\n    </tr>\n    <tr>\n      <th>Bo Bichette</th>\n      <td>TOR</td>\n      <td>SS</td>\n      <td>23</td>\n      <td>93</td>\n      <td>380</td>\n      <td>73</td>\n      <td>110</td>\n      <td>18</td>\n      <td>1</td>\n      <td>16</td>\n      <td>...</td>\n      <td>0</td>\n      <td>25</td>\n      <td>86</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.289</td>\n      <td>0.339</td>\n      <td>0.468</td>\n      <td>0.807</td>\n    </tr>\n    <tr>\n      <th>Adam Frazier</th>\n      <td>PIT</td>\n      <td>2B</td>\n      <td>29</td>\n      <td>96</td>\n      <td>377</td>\n      <td>56</td>\n      <td>123</td>\n      <td>27</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>4</td>\n      <td>34</td>\n      <td>45</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0.326</td>\n      <td>0.390</td>\n      <td>0.451</td>\n      <td>0.841</td>\n    </tr>\n    <tr>\n      <th>Whit Merrifield</th>\n      <td>KC</td>\n      <td>2B</td>\n      <td>32</td>\n      <td>95</td>\n      <td>377</td>\n      <td>54</td>\n      <td>103</td>\n      <td>21</td>\n      <td>2</td>\n      <td>8</td>\n      <td>...</td>\n      <td>1</td>\n      <td>28</td>\n      <td>56</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>0.273</td>\n      <td>0.321</td>\n      <td>0.403</td>\n      <td>0.724</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Import Dataset\n",
    "file_path_21 = Path(\"Resources/batting_stats_2021.csv\")\n",
    "file_path_20 = Path(\"Resources/batting_stats_2020.csv\")\n",
    "file_path_19 = Path(\"Resources/batting_stats_2019.csv\")\n",
    "file_path_18 = Path(\"Resources/batting_stats_2018.csv\")\n",
    "file_path_17 = Path(\"Resources/batting_stats_2017.csv\")\n",
    "file_path_16 = Path(\"Resources/batting_stats_2016.csv\")\n",
    "file_path_15 = Path(\"Resources/batting_stats_2015.csv\")\n",
    "file_path_14 = Path(\"Resources/batting_stats_2014.csv\")\n",
    "file_path_13 = Path(\"Resources/batting_stats_2013.csv\")\n",
    "file_path_12 = Path(\"Resources/batting_stats_2012.csv\")\n",
    "file_path_11 = Path(\"Resources/batting_stats_2011.csv\")\n",
    "file_path_10 = Path(\"Resources/batting_stats_2010.csv\")\n",
    "\n",
    "# Read into Dataset\n",
    "stats_21_df = pd.read_csv(file_path_21, index_col = 0)\n",
    "stats_20_df = pd.read_csv(file_path_20, index_col = 0)\n",
    "stats_19_df = pd.read_csv(file_path_19, index_col = 0)\n",
    "stats_18_df = pd.read_csv(file_path_18, index_col = 0)\n",
    "stats_17_df = pd.read_csv(file_path_17, index_col = 0)\n",
    "stats_16_df = pd.read_csv(file_path_16, index_col = 0)\n",
    "stats_15_df = pd.read_csv(file_path_15, index_col = 0)\n",
    "stats_14_df = pd.read_csv(file_path_14, index_col = 0)\n",
    "stats_13_df = pd.read_csv(file_path_13, index_col = 0)\n",
    "stats_12_df = pd.read_csv(file_path_12, index_col = 0)\n",
    "stats_11_df = pd.read_csv(file_path_11, index_col = 0)\n",
    "stats_10_df = pd.read_csv(file_path_10, index_col = 0)\n",
    "\n",
    "stats_21_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X & y variables\n",
    "X = stats_21_df.iloc[:, 4:22]\n",
    "y = stats_21_df[\"OBP\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "number_input_features = 19\n",
    "hidden_nodes_layer1 = 38\n",
    "hidden_nodes_layer2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(\n",
    "    Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Layer 2\n",
    "model.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andy L\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (358, 18, 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3aaf9ab6d12b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2651\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    374\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (358, 18, 1)"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 50\n",
    "training_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}